ggplot2::geom_smooth(method = "lm", se = {{se}}, size = {{size}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(index, .std.resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::theme_minimal()
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, nrow = 2)
}
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
library(tidyverse)
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_mod <- glm(cyl ~ wt + mpg, cars_cars,
family = 'binomial')
ggplot(glm_mod, aes(seq_along(.cooksd), .cooksd)) +
geom_bar(stat = 'identity')
ggplot(glm_mod, aes( .cooksd)) +
geom_bar(stat = 'identity')
ggplot(glm_mod, aes( .cooksd)) +
geom_bar()
cooks.distance(glm_mod)
as.data.frame(cooks.distance(glm_mod))
as.data.frame(cook_distance = cooks.distance(glm_mod)) %>%
ggplot(aes())
as.data.frame(cooks.distance(glm_mod)) %>%
ggplot(aes())
as.data.frame(cooks.distance(glm_mod))
glimpse(mtcars)
names(mtcars)
as.data.frame(cooks.distance(glm_mod)) %>%
rowid_to_column() %>%
mutate(cook_dist = cooks.distance(glm_mod)) %>%
ggplot(aes(rowid, cook_dist)) +
geom_point()
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
size = 1.25,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, size = {{size}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, size = {{size}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(index, .stdresid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::theme_minimal()
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, nrow = 2)
}
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
size = 1.25,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, size = {{size}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, size = {{size}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(index, .std.resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::theme_minimal()
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, nrow = 2)
}
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, size = {{size}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, size = {{size}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(index, .std.resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::theme_minimal()
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, nrow = 2)
}
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(index, .std.resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::theme_minimal()
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, nrow = 2)
}
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
?theme
broom::augment(glm_mod)
str(broom::augment(glm_mod))
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(.rownames, .std.resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = 'Standardized Residuals') +
ggplot2::theme(legend.position = 'none')
cooks <- model_data %>%
ggplot2::ggplot(aes(.rownames, .cooksd)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = 'Cook's Distance) +
ggplot2::theme(legend.position = 'none')
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, nrow = 3)
}
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(.rownames, .std.resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = 'Standardized Residuals') +
ggplot2::theme(legend.position = 'none')
cooks <- model_data %>%
ggplot2::ggplot(aes(.rownames, .cooksd)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = "Cook's Distance") +
ggplot2::theme(legend.position = 'none')
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, cooks, nrow = 3)
}
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(.rownames, .std.resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = 'Standardized Residuals') +
ggplot2::coord_flip() +
ggplot2::theme(legend.position = 'none')
cooks <- model_data %>%
ggplot2::ggplot(aes(.rownames, .cooksd)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = "Cook's Distance") +
ggplot2::coord_flip() +
ggplot2::theme(legend.position = 'none')
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, cooks, nrow = 3)
}
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(index, .std.resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = 'Standardized Residuals') +
ggplot2::coord_flip() +
ggplot2::theme(legend.position = 'none')
cooks <- model_data %>%
ggplot2::ggplot(aes(index, .cooksd)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = "Cook's Distance") +
ggplot2::coord_flip() +
ggplot2::theme(legend.position = 'none')
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, cooks, nrow = 3)
}
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
glm_assump <- function(data,
x,
y,
alpha = .5,
se = FALSE,
loess_color = 'dodgerblue',
line_color = 'black'){
library(magrittr)
y <- deparse(substitute(y))
ivs <- paste(x, collapse = " + ")
my_formula <- as.formula(paste(y, "~", ivs))
model <- glm(my_formula, data = data, family = "binomial")
plot_data <- predict(model, type = "response")
model_predictors <- colnames(data)
data <- {{data}} %>%
tidyr::drop_na({{x}}, {{y}}) %>%
dplyr::select({{x}}, {{y}}) %>%
dplyr::mutate(logit = log(plot_data/(1 - plot_data))) %>%
tidyr::pivot_longer(cols = !logit,
names_to = "predict_variables",
values_to = "predictor_values") #change to pivot longer
scatterplot <- data %>%
ggplot2::ggplot(aes(logit, predictor_values)) +
ggplot2::geom_point(alpha = {{alpha}}) +
ggplot2::geom_smooth(method = "loess", se = {{se}}, color = {{loess_color}}) +
ggplot2::geom_smooth(method = "lm", se = {{se}}, color = {{line_color}}) +
ggplot2::facet_wrap(vars(predict_variables),
scales = "free_y")
model_data <- broom::augment(model) %>%
dplyr::mutate(index = 1:n())
outlier <- model_data %>%
ggplot2::ggplot(aes(index, .resid)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = 'Standardized Residuals') +
ggplot2::coord_flip() +
ggplot2::theme(legend.position = 'none')
cooks <- model_data %>%
ggplot2::ggplot(aes(index, .cooksd)) +
ggplot2::geom_point(aes(color = {{y}}), alpha = {{alpha}}) +
ggplot2::labs(title = "Cook's Distance") +
ggplot2::coord_flip() +
ggplot2::theme(legend.position = 'none')
message('Make sure your outcome is binary.')
gridExtra::grid.arrange(scatterplot, outlier, cooks, nrow = 3)
}
cars_cars <- mtcars %>%
filter(cyl != 6) %>%
mutate(cyl = case_when(cyl == 4 ~ 0,
cyl == 8 ~ 1))
glm_assump(data = cars_cars,
x = c('wt', 'mpg'),
y = cyl)
??moran.mc
spat_error_model_resid <- function(data,
model,
color = 'dodgerblue',
listw,
zero.policy = c(TRUE, FALSE),
nsim = 9999,
seed = 12345){
visual <- ggplot2::ggplot(data = data, aes(x = model$residuals, y = model$fitted.values)) +
ggplot2::geom_point() +
ggplot2::geom_hline(yintercept = mean(model$fitted.values),
color = color)
set.seed(seed)
moran_find <- spdep::moran.mc(model$residuals, listw = listw, zero.policy = zero.policy, nsim = nsim)
statistics <- if(moran_find$statistic < 0){
upper <- (1 - moran_find$p.value)
upper*2
} else{
moran_find$p.value*2
}
message("p value for Moran's I statistic is for a two-tailed test.")
warning('Model should be a spatial error model.')
return(list(visual, statistics))
}
